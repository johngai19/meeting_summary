#!/usr/bin/env python3
"""
çŸ¥è¯†åº“æµ‹è¯•è„šæœ¬
"""
import os
import sys
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

def create_test_documents():
    """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
    test_docs = []
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp(prefix="kb_test_")
    
    # æµ‹è¯•æ–‡æ¡£1ï¼šä¼šè®®çºªè¦
    meeting_content = """# é¡¹ç›®å¯åŠ¨ä¼šè®®çºªè¦

**æ—¶é—´**: 2024-01-15 14:00
**å‚ä¸äººå‘˜**: å¼ ç»ç†ã€æå·¥ç¨‹å¸ˆã€ç‹è®¾è®¡å¸ˆ

## è®¨è®ºå†…å®¹
1. é¡¹ç›®ç›®æ ‡ç¡®è®¤
2. æŠ€æœ¯æ–¹æ¡ˆè®¨è®º
3. æ—¶é—´èŠ‚ç‚¹å®‰æ’

## å†³ç­–äº‹é¡¹
- é‡‡ç”¨å‰åç«¯åˆ†ç¦»æ¶æ„
- ä½¿ç”¨Python Flaskåç«¯
- é¢„è®¡å¼€å‘å‘¨æœŸ3ä¸ªæœˆ

## è¡ŒåŠ¨è®¡åˆ’
- æå·¥ç¨‹å¸ˆè´Ÿè´£åç«¯å¼€å‘
- ç‹è®¾è®¡å¸ˆè´Ÿè´£UIè®¾è®¡
- ä¸‹å‘¨ä¸€æäº¤è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ
"""
    
    meeting_file = os.path.join(temp_dir, "meeting_20240115.md")
    with open(meeting_file, 'w', encoding='utf-8') as f:
        f.write(meeting_content)
    test_docs.append(('meeting_minutes', meeting_file))
    
    # æµ‹è¯•æ–‡æ¡£2ï¼šæŠ€æœ¯æ ‡å‡†
    standard_content = """# å¼€å‘è§„èŒƒæ–‡æ¡£

## ä»£ç è§„èŒƒ
1. ä½¿ç”¨Python PEP8ç¼–ç æ ‡å‡†
2. å‡½æ•°å‘½åé‡‡ç”¨snake_case
3. ç±»å‘½åé‡‡ç”¨PascalCase

## æ–‡æ¡£è§„èŒƒ
- æ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰docstring
- é‡è¦é€»è¾‘éœ€è¦æ·»åŠ æ³¨é‡Š
- READMEæ–‡æ¡£å¿…é¡»åŒ…å«å®‰è£…å’Œä½¿ç”¨è¯´æ˜

## æµ‹è¯•è§„èŒƒ
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡ä¸ä½äº80%
- å…³é”®åŠŸèƒ½å¿…é¡»æœ‰é›†æˆæµ‹è¯•
"""
    
    standard_file = os.path.join(temp_dir, "dev_standards.md")
    with open(standard_file, 'w', encoding='utf-8') as f:
        f.write(standard_content)
    test_docs.append(('standards', standard_file))
    
    # æµ‹è¯•æ–‡æ¡£3ï¼šå·¥ä½œè®¡åˆ’
    plan_content = """# Q1å·¥ä½œè®¡åˆ’

## 1æœˆç›®æ ‡
- å®Œæˆéœ€æ±‚åˆ†æ
- æ­å»ºå¼€å‘ç¯å¢ƒ
- åˆ¶å®šæŠ€æœ¯æ–¹æ¡ˆ

## 2æœˆç›®æ ‡  
- å®Œæˆæ ¸å¿ƒåŠŸèƒ½å¼€å‘
- è¿›è¡Œå•å…ƒæµ‹è¯•
- å®Œæˆå‰ç«¯ç•Œé¢

## 3æœˆç›®æ ‡
- ç³»ç»Ÿé›†æˆæµ‹è¯•
- æ€§èƒ½ä¼˜åŒ–
- ç”¨æˆ·éªŒæ”¶æµ‹è¯•

## é£é™©æ§åˆ¶
- æŠ€æœ¯éš¾ç‚¹æå‰æ”»å…³
- å®šæœŸè¿›åº¦review
- åŠæ—¶è°ƒæ•´è®¡åˆ’
"""
    
    plan_file = os.path.join(temp_dir, "q1_plan.md")
    with open(plan_file, 'w', encoding='utf-8') as f:
        f.write(plan_content)
    test_docs.append(('plans', plan_file))
    
    print(f"æµ‹è¯•æ–‡æ¡£åˆ›å»ºåœ¨: {temp_dir}")
    return test_docs, temp_dir

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("=" * 50)
    print("å¼€å§‹æµ‹è¯•çŸ¥è¯†åº“åŸºæœ¬åŠŸèƒ½")
    print("=" * 50)
    
    temp_dir = None
    try:
        # å¯¼å…¥çŸ¥è¯†åº“
        from knowledge_base.core import EnhancedKnowledgeBase
        
        print("âœ… æˆåŠŸå¯¼å…¥çŸ¥è¯†åº“æ¨¡å—")
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰
        print("\næ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰...")
        kb = EnhancedKnowledgeBase(use_simple_embeddings=True)
        print("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        print("\næ­£åœ¨åˆ›å»ºæµ‹è¯•æ–‡æ¡£...")
        test_docs, temp_dir = create_test_documents()
        print("âœ… æµ‹è¯•æ–‡æ¡£åˆ›å»ºæˆåŠŸ")
        
        # æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        print("\næ­£åœ¨æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“...")
        org_name = "æµ‹è¯•ç»„ç»‡"
        
        success_count = 0
        for doc_type, file_path in test_docs:
            success = kb.add_document(
                file_path=file_path,
                organization=org_name,
                doc_type=doc_type,
                title=os.path.basename(file_path)
            )
            if success:
                print(f"âœ… æˆåŠŸæ·»åŠ : {os.path.basename(file_path)}")
                success_count += 1
            else:
                print(f"âŒ æ·»åŠ å¤±è´¥: {os.path.basename(file_path)}")
        
        if success_count == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸæ·»åŠ ä»»ä½•æ–‡æ¡£")
            return False
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        print("\næ­£åœ¨æµ‹è¯•æœç´¢åŠŸèƒ½...")
        test_query = "é¡¹ç›®å¼€å‘è®¡åˆ’å’ŒæŠ€æœ¯æ–¹æ¡ˆ"
        results = kb.search_relevant_documents(
            query=test_query,
            organization=org_name,
            k=3
        )
        
        print(f"æœç´¢æŸ¥è¯¢: {test_query}")
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, (doc, score) in enumerate(results, 1):
            source = doc.metadata.get('source_file', 'æœªçŸ¥')
            doc_type = doc.metadata.get('doc_type', 'æœªçŸ¥')
            print(f"  {i}. {source} ({doc_type}) - ç›¸ä¼¼åº¦: {score:.3f}")
            print(f"     å†…å®¹é¢„è§ˆ: {doc.page_content[:100]}...")
        
        # æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡ç”Ÿæˆ
        print("\næ­£åœ¨æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡ç”Ÿæˆ...")
        meeting_content = "æˆ‘ä»¬éœ€è¦è®¨è®ºé¡¹ç›®çš„æŠ€æœ¯æ¶æ„å’Œå¼€å‘è§„èŒƒ"
        context = kb.get_intelligent_context(
            meeting_content=meeting_content,
            organization=org_name
        )
        
        print("ç”Ÿæˆçš„æ™ºèƒ½ä¸Šä¸‹æ–‡:")
        print(context[:500] + "..." if len(context) > 500 else context)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:")
        stats = kb.get_stats()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        print("\nğŸ‰ çŸ¥è¯†åº“æµ‹è¯•å®Œæˆ!")
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–:")
        print("  pip install langchain langchain-community langchain-openai langchain-text-splitters chromadb")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
                print(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
            except:
                pass

if __name__ == "__main__":
    success = test_basic_functionality()
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡! çŸ¥è¯†åº“åŠŸèƒ½æ­£å¸¸")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥! è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")