from flask import Flask, render_template, request, send_file, redirect, url_for, jsonify
from flask_socketio import SocketIO, emit
import os
import subprocess
import whisper
try:
    import openai
except ImportError:
    openai = None
import requests
import json
from datetime import datetime
import fitz
from fitz import Document
import pytesseract
from PIL import Image
import pandas as pd
import tempfile
from typing import cast, Optional, Dict, List
import logging
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass
import uuid
import threading
import time

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
app.config['UPLOAD_FOLDER'] = tempfile.mkdtemp()
socketio = SocketIO(app, cors_allowed_origins="*")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–æ¨¡å‹
logger.info("æ­£åœ¨åˆå§‹åŒ–Whisperæ¨¡å‹...")
whisper_model = whisper.load_model('medium')  # å‡çº§ä¸ºmediumæ¨¡å‹
logger.info("Whisperæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

# OpenAIé…ç½®
if openai:
    openai.api_key = os.getenv('OPENAI_API_KEY')
OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')

class ProcessingProgress:
    def __init__(self):
        self.steps = []
        self.current_step = 0
        self.total_steps = 0
        self.session_id: Optional[str] = None
        
    def add_step(self, step_name: str, description: str = ""):
        self.steps.append({
            'name': step_name,
            'description': description,
            'status': 'pending',
            'start_time': None,
            'end_time': None
        })
        self.total_steps = len(self.steps)
        
    def start_step(self, step_index: int):
        if 0 <= step_index < len(self.steps):
            self.current_step = step_index
            self.steps[step_index]['status'] = 'processing'
            self.steps[step_index]['start_time'] = datetime.now()
            step_name = self.steps[step_index]['name']
            logger.info(f"ğŸš€ [{self.session_id[:8] if self.session_id else 'LOCAL'}] å¼€å§‹: {step_name}")
            self.emit_progress()
            
    def complete_step(self, step_index: int):
        if 0 <= step_index < len(self.steps):
            self.steps[step_index]['status'] = 'completed'
            self.steps[step_index]['end_time'] = datetime.now()
            step_name = self.steps[step_index]['name']
            duration = (self.steps[step_index]['end_time'] - self.steps[step_index]['start_time']).total_seconds()
            logger.info(f"âœ… [{self.session_id[:8] if self.session_id else 'LOCAL'}] å®Œæˆ: {step_name} (è€—æ—¶ {duration:.1f}ç§’)")
            self.emit_progress()
            
    def emit_progress(self):
        if self.session_id:
            # å¤„ç†datetimeåºåˆ—åŒ–é—®é¢˜
            serialized_steps = []
            for step in self.steps:
                serialized_step = {
                    'name': step['name'],
                    'description': step['description'],
                    'status': step['status'],
                    'start_time': step['start_time'].isoformat() if step['start_time'] else None,
                    'end_time': step['end_time'].isoformat() if step['end_time'] else None
                }
                serialized_steps.append(serialized_step)
            
            progress_data = {
                'current_step': self.current_step,
                'total_steps': self.total_steps,
                'steps': serialized_steps,
                'percentage': (self.current_step / self.total_steps * 100) if self.total_steps > 0 else 0
            }
            
            # å‘½ä»¤è¡Œç›‘æ§è¾“å‡º
            current_step_name = self.steps[self.current_step]['name'] if self.current_step < len(self.steps) else "å®Œæˆ"
            logger.info(f"ğŸ”„ [{self.session_id[:8]}] è¿›åº¦: {progress_data['percentage']:.1f}% - {current_step_name}")
            
            socketio.emit('progress_update', progress_data, to=self.session_id)

def call_openai_api(prompt: str, model: str = "gpt-3.5-turbo", max_tokens: int = 2000) -> Optional[str]:
    """è°ƒç”¨OpenAI API"""
    try:
        if not openai or not hasattr(openai, 'api_key'):
            logger.warning("ğŸš« OpenAI not available")
            return None
            
        if not openai.api_key:
            logger.warning("ğŸ”‘ OpenAI API key not configured")
            return None
            
        logger.info(f"ğŸ¤– è°ƒç”¨OpenAI API - æ¨¡å‹: {model}, è¾“å…¥é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a professional meeting assistant specialized in transcription correction and meeting summary generation."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=0.7
        )
        
        content = response.choices[0].message.content
        result = content.strip() if content else ""
        logger.info(f"âœ… OpenAI API è°ƒç”¨æˆåŠŸ - è¾“å‡ºé•¿åº¦: {len(result)} å­—ç¬¦")
        return result
    except Exception as e:
        logger.error(f"âŒ OpenAI API call failed: {str(e)}")
        return None

def call_ollama_api(prompt: str, model: str = "llama2", max_tokens: int = 2000) -> Optional[str]:
    """è°ƒç”¨æœ¬åœ°ollamaæ¨¡å‹"""
    try:
        logger.info(f"ğŸ¦™ è°ƒç”¨Ollama API - æ¨¡å‹: {model}, è¾“å…¥é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "num_predict": max_tokens,
                    "temperature": 0.7
                }
            },
            timeout=300
        )
        
        if response.status_code == 200:
            result = response.json().get('response', '').strip()
            logger.info(f"âœ… Ollama API è°ƒç”¨æˆåŠŸ - è¾“å‡ºé•¿åº¦: {len(result)} å­—ç¬¦")
            return result
        else:
            logger.error(f"âŒ Ollama API call failed with status {response.status_code}")
            return None
    except Exception as e:
        logger.error(f"âŒ Ollama API call failed: {str(e)}")
        return None

def correct_transcription(transcript: str, reference_docs: List[str], progress: ProcessingProgress, step_index: int) -> str:
    """ä½¿ç”¨AIæ¨¡å‹çº æ­£è½¬å½•æ–‡æœ¬"""
    progress.start_step(step_index)
    
    # å¦‚æœæ²¡æœ‰å‚è€ƒæ–‡æ¡£ï¼Œç›´æ¥è¿”å›åŸå§‹è½¬å½•
    if not reference_docs:
        logger.info("ğŸ“ æ²¡æœ‰å‚è€ƒæ–‡æ¡£ï¼Œè·³è¿‡AIçº é”™")
        progress.complete_step(step_index)
        return transcript
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒæ–‡æ¡£ï¼Œå¯¹ä¼šè®®è½¬å½•æ–‡æœ¬è¿›è¡Œçº æ­£å’Œæ”¹è¿›ã€‚ä¸»è¦å…³æ³¨ï¼š
1. ä¿®æ­£è¯­éŸ³è½¬æ–‡å­—çš„é”™è¯¯
2. æ”¹è¿›è¯­æ³•å’Œè¡¨è¾¾
3. è¡¥å……ä¸“ä¸šæœ¯è¯­
4. ä¿æŒåŸæ„ä¸å˜

å‚è€ƒæ–‡æ¡£ï¼š
{chr(10).join(reference_docs)}

åŸå§‹è½¬å½•æ–‡æœ¬ï¼š
{transcript}

è¯·æä¾›çº æ­£åçš„è½¬å½•æ–‡æœ¬ï¼š
"""
    
    # ä¼˜å…ˆä½¿ç”¨OpenAIï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ollama
    corrected_text = call_openai_api(prompt)
    if not corrected_text:
        logger.info("ğŸ”„ OpenAIä¸å¯ç”¨ï¼Œå°è¯•Ollama")
        corrected_text = call_ollama_api(prompt)
    
    if not corrected_text:
        logger.warning("âš ï¸ æ‰€æœ‰AIæœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹æ–‡æœ¬")
        corrected_text = transcript
    
    progress.complete_step(step_index)
    return corrected_text

def generate_meeting_summary(corrected_transcript: str, reference_docs: List[str], progress: ProcessingProgress, step_index: int) -> Dict[str, str]:
    """ç”Ÿæˆè¯¦ç»†çš„ä¼šè®®çºªè¦"""
    progress.start_step(step_index)
    
    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®è½¬å½•æ–‡æœ¬å’Œå‚è€ƒæ–‡æ¡£ï¼Œç”Ÿæˆè¯¦ç»†çš„ä¼šè®®çºªè¦ã€‚è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ä¼šè®®æ¦‚è¦
[ç®€è¦æ¦‚è¿°ä¼šè®®ç›®çš„å’Œä¸»è¦è®®é¢˜]

## ä¼šè®®é‡ç‚¹
[åˆ—å‡ºä¼šè®®çš„å…³é”®è®¨è®ºç‚¹å’Œé‡è¦ä¿¡æ¯]

## å·¥ä½œå†³è®®
[æ˜ç¡®çš„å†³ç­–å’Œå†³å®šäº‹é¡¹]

## å½“å‰è¿›åº¦
[å·²å®Œæˆçš„å·¥ä½œå’Œå½“å‰çŠ¶æ€]

## åç»­è®¡åˆ’
[æœªæ¥çš„å·¥ä½œè®¡åˆ’å’Œæ—¶é—´å®‰æ’]

## å¾…åŠäº‹é¡¹
[å…·ä½“çš„è¡ŒåŠ¨é¡¹ç›®ï¼ŒåŒ…æ‹¬è´Ÿè´£äººå’Œæˆªæ­¢æ—¥æœŸ]

å‚è€ƒæ–‡æ¡£ï¼š
{chr(10).join(reference_docs) if reference_docs else "æ— å‚è€ƒæ–‡æ¡£"}

ä¼šè®®è½¬å½•æ–‡æœ¬ï¼š
{corrected_transcript}

è¯·ç”Ÿæˆè¯¦ç»†çš„ä¼šè®®çºªè¦ï¼š
"""
    
    # è°ƒç”¨AIç”Ÿæˆçºªè¦
    summary = call_openai_api(prompt, max_tokens=3000)
    if not summary:
        logger.info("ğŸ”„ OpenAIä¸å¯ç”¨ï¼Œå°è¯•Ollamaç”Ÿæˆçºªè¦")
        summary = call_ollama_api(prompt, max_tokens=3000)
    
    if not summary:
        logger.warning("âš ï¸ æ‰€æœ‰AIæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ ¼å¼ç”Ÿæˆçºªè¦")
        # åˆ›å»ºåŸºç¡€çš„ä¼šè®®çºªè¦
        transcript_preview = corrected_transcript[:800] + "..." if len(corrected_transcript) > 800 else corrected_transcript
        
        summary = f"""## ä¼šè®®æ¦‚è¦
æœ¬æ¬¡ä¼šè®®è¿›è¡Œäº†ç›¸å…³å·¥ä½œè®¨è®ºå’Œå®‰æ’ã€‚

## ä¼šè®®é‡ç‚¹
{transcript_preview}

## å·¥ä½œå†³è®®
æ ¹æ®ä¼šè®®è®¨è®ºå†…å®¹ï¼Œå½¢æˆç›¸å…³å†³è®®ã€‚

## å½“å‰è¿›åº¦
ä¼šè®®ä¸­æ±‡æŠ¥äº†å½“å‰å·¥ä½œè¿›å±•ã€‚

## åç»­è®¡åˆ’
åˆ¶å®šäº†åç»­å·¥ä½œè®¡åˆ’å’Œå®‰æ’ã€‚

## å¾…åŠäº‹é¡¹
ä¼šè®®ç¡®å®šäº†ç›¸å…³å¾…åŠäº‹é¡¹ã€‚

_æ³¨ï¼šæ­¤çºªè¦ä¸ºåŸºç¡€æ ¼å¼ï¼Œå»ºè®®é…ç½®AIæœåŠ¡ä»¥è·å¾—æ›´è¯¦ç»†çš„ä¼šè®®çºªè¦ã€‚_"""
    
    progress.complete_step(step_index)
    return {"summary": summary}

def extract_text_from_file(file_path: str) -> str:
    """ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.pdf':
            doc = fitz.open(file_path)
            text = ""
            for page_num in range(len(doc)):
                page = doc[page_num]
                text += page.get_text()  # type: ignore
            doc.close()
            return text
        elif file_ext in ['.md', '.txt']:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            logger.warning(f"Unsupported file type: {file_ext}")
            return ""
    except Exception as e:
        logger.error(f"Error extracting text from {file_path}: {str(e)}")
        return ""

@app.route('/')
def index():
    return render_template('index.html')

@socketio.on('connect')
def handle_connect():
    logger.info(f"Client connected: {request.sid}")  # type: ignore

@socketio.on('disconnect')
def handle_disconnect():
    logger.info(f"Client disconnected: {request.sid}")  # type: ignore

@app.route('/process', methods=['POST'])
def process_meeting():
    session_id = str(uuid.uuid4())
    
    try:
        # è·å–è¡¨å•æ•°æ®
        video = request.files.get('video')
        docs = request.files.getlist('docs')
        text_input = request.form.get('docsText', '')
        
        if not video or not video.filename:
            return jsonify({"error": "è¯·é€‰æ‹©è§†é¢‘æ–‡ä»¶"}), 400
        
        # åœ¨ä¸»çº¿ç¨‹ä¸­ä¿å­˜æ–‡ä»¶ï¼Œé¿å…å¼‚æ­¥çº¿ç¨‹ä¸­çš„æ–‡ä»¶è®¿é—®é—®é¢˜
        video_filename = video.filename
        base_name = os.path.splitext(video_filename)[0]
        mov_path = os.path.join(app.config['UPLOAD_FOLDER'], video_filename)
        video.save(mov_path)
        
        # å¤„ç†æ–‡æ¡£æ–‡ä»¶
        doc_files = []
        for doc in docs:
            if doc and doc.filename:
                doc_path = os.path.join(app.config['UPLOAD_FOLDER'], doc.filename)
                doc.save(doc_path)
                doc_files.append({'filename': doc.filename, 'path': doc_path})
        
        # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­å¤„ç†ï¼Œé¿å…é˜»å¡
        thread = threading.Thread(target=process_meeting_async, args=(session_id, mov_path, video_filename, doc_files, text_input))
        thread.start()
        
        return jsonify({"session_id": session_id, "status": "processing"})
    
    except Exception as e:
        logger.error(f"âŒ å¤„ç†è¯·æ±‚é”™è¯¯: {str(e)}")
        return jsonify({"error": f"å¤„ç†è¯·æ±‚é”™è¯¯: {str(e)}"}), 500

def process_meeting_async(session_id: str, mov_path: str, video_filename: str, doc_files: list, text_input: str):
    """å¼‚æ­¥å¤„ç†ä¼šè®®"""
    progress = ProcessingProgress()
    progress.session_id = session_id
    
    logger.info(f"ğŸ¬ [{session_id[:8]}] å¼€å§‹å¤„ç†ä¼šè®® - è§†é¢‘: {video_filename}")
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
    
    try:
        # è®¾ç½®å¤„ç†æ­¥éª¤
        progress.add_step("video_upload", "ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
        progress.add_step("audio_extraction", "æå–éŸ³é¢‘")
        progress.add_step("transcription", "è¯­éŸ³è½¬æ–‡å­—")
        progress.add_step("doc_processing", "å¤„ç†å‚è€ƒæ–‡æ¡£")
        progress.add_step("text_correction", "çº æ­£è½¬å½•æ–‡æœ¬")
        progress.add_step("summary_generation", "ç”Ÿæˆä¼šè®®çºªè¦")
        progress.add_step("report_creation", "åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶")
        
        # æ­¥éª¤1ï¼šå¤„ç†è§†é¢‘æ–‡ä»¶ï¼ˆå·²ç»åœ¨ä¸»çº¿ç¨‹ä¸­å®Œæˆï¼‰
        progress.start_step(0)
        base_name = os.path.splitext(video_filename)[0]
        
        # è·å–æ–‡ä»¶å¤§å°
        if os.path.exists(mov_path):
            file_size = os.path.getsize(mov_path)
            logger.info(f"ğŸ“ [{session_id[:8]}] è§†é¢‘æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.1f} MB")
        else:
            logger.error(f"âŒ [{session_id[:8]}] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {mov_path}")
            socketio.emit('error', {'message': 'è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨'}, to=session_id)
            return
        progress.complete_step(0)
        
        # æ­¥éª¤2ï¼šæå–éŸ³é¢‘
        progress.start_step(1)
        audio_path = os.path.join(app.config['UPLOAD_FOLDER'], f'{base_name}_audio.wav')
        subprocess.run(['ffmpeg', '-i', mov_path, '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', audio_path], 
                      check=True, capture_output=True)
        progress.complete_step(1)
        
        # æ­¥éª¤3ï¼šè¯­éŸ³è½¬æ–‡å­—
        progress.start_step(2)
        result = whisper_model.transcribe(audio_path, language=None)  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
        transcript = str(result["text"])
        
        # æ£€æµ‹è¯­è¨€å’Œè½¬å½•é•¿åº¦
        detected_lang = result.get("language", "unknown")
        logger.info(f"ğŸ¤ [{session_id[:8]}] è½¬å½•å®Œæˆ - è¯­è¨€: {detected_lang}, å­—ç¬¦æ•°: {len(transcript)}")
        progress.complete_step(2)
        
        # æ­¥éª¤4ï¼šå¤„ç†å‚è€ƒæ–‡æ¡£
        progress.start_step(3)
        doc_texts = []
        
        # å¤„ç†æ–‡æœ¬è¾“å…¥
        if text_input and text_input.strip():
            doc_texts.append(text_input.strip())
            logger.info(f"ğŸ“ [{session_id[:8]}] æ·»åŠ æ–‡æœ¬è¾“å…¥: {len(text_input.strip())} å­—ç¬¦")
        
        # å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£
        for doc_info in doc_files:
            try:
                text = extract_text_from_file(doc_info['path'])
                if text:
                    doc_texts.append(text)
                    logger.info(f"ğŸ“„ [{session_id[:8]}] å¤„ç†æ–‡æ¡£: {doc_info['filename']}, æå– {len(text)} å­—ç¬¦")
            except Exception as e:
                logger.warning(f"âš ï¸ [{session_id[:8]}] æ–‡æ¡£å¤„ç†å¤±è´¥: {doc_info['filename']}, é”™è¯¯: {str(e)}")
        
        logger.info(f"ğŸ“š [{session_id[:8]}] å‚è€ƒæ–‡æ¡£å¤„ç†å®Œæˆ - å…± {len(doc_texts)} ä¸ªæ–‡æ¡£")
        progress.complete_step(3)
        
        # æ­¥éª¤5ï¼šçº æ­£è½¬å½•æ–‡æœ¬
        corrected_transcript = correct_transcription(transcript, doc_texts, progress, 4)
        
        # æ­¥éª¤6ï¼šç”Ÿæˆä¼šè®®çºªè¦
        meeting_summary = generate_meeting_summary(corrected_transcript, doc_texts, progress, 5)
        
        # æ­¥éª¤7ï¼šåˆ›å»ºæŠ¥å‘Šæ–‡ä»¶
        progress.start_step(6)
        
        # ç”Ÿæˆçº æ­£åçš„è½¬å½•æ–‡ä»¶
        corrected_path = os.path.join(app.config['UPLOAD_FOLDER'], f'{base_name}_corrected_transcript.md')
        with open(corrected_path, 'w', encoding='utf-8') as f:
            f.write(f'# çº æ­£åçš„ä¼šè®®è½¬å½•\n\n')
            f.write(f'**ä¼šè®®æ—¥æœŸ**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n\n')
            f.write(f'## åŸå§‹è½¬å½•\n{transcript}\n\n')
            f.write(f'## çº æ­£åè½¬å½•\n{corrected_transcript}\n\n')
        
        # ç”Ÿæˆå®Œæ•´çš„ä¼šè®®æŠ¥å‘Š
        report_path = os.path.join(app.config['UPLOAD_FOLDER'], f'{base_name}_meeting_report.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f'# ä¼šè®®æŠ¥å‘Š\n\n')
            f.write(f'**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n\n')
            f.write(f'## çº æ­£åçš„è½¬å½•æ–‡æœ¬\n{corrected_transcript}\n\n')
            f.write(f'{meeting_summary["summary"]}\n\n')
        
        progress.complete_step(6)
        
        # é€šçŸ¥å¤„ç†å®Œæˆ
        total_time = time.time() - start_time
        logger.info(f"ğŸ‰ [{session_id[:8]}] å¤„ç†å®Œæˆ! æ€»è€—æ—¶: {total_time:.1f}ç§’")
        logger.info(f"ğŸ“„ [{session_id[:8]}] ç”Ÿæˆæ–‡ä»¶: {os.path.basename(corrected_path)}, {os.path.basename(report_path)}")
        
        socketio.emit('processing_complete', {
            'corrected_transcript_path': corrected_path,
            'report_path': report_path
        }, to=session_id)
        
    except Exception as e:
        logger.error(f"ğŸ’¥ [{session_id[:8]}] å¤„ç†é”™è¯¯: {str(e)}")
        socketio.emit('error', {'message': f'å¤„ç†é”™è¯¯: {str(e)}'}, to=session_id)

@app.route('/download/<filename>')
def download_file(filename):
    """ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶"""
    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
    if os.path.exists(file_path):
        return send_file(file_path, as_attachment=True)
    else:
        return "æ–‡ä»¶ä¸å­˜åœ¨", 404

if __name__ == '__main__':
    socketio.run(app, debug=True, port=5000)